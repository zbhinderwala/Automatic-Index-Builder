{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5412, 9)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#### Reading the training properties file ####\n",
    "training_properties = pd.read_csv(\"Training_Properties.csv\", low_memory=False)\n",
    "\n",
    "\n",
    "#### Reading the Clusters.csv ####\n",
    "training_clusters = pd.read_csv(\"Training_Clusters.csv\", low_memory=False)\n",
    "\n",
    "training_final['word'] = training_final['word'].str.lower()\n",
    "training_final = training_final.drop_duplicates(['word'],keep='first')\n",
    "\n",
    "#### Merging the clusters and training to include only the centroids as a part of training set ####\n",
    "training_final = pd.merge(training_properties, training_clusters, how = 'left', left_on=['word','source'], right_on = ['word','source'])\n",
    "training_final = training_final.dropna()\n",
    "training_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#### Processing the data - adding features ####\n",
    "\n",
    "#### Adding tf_idf ( term frequency - inverse document frequency ) to the training set ####\n",
    "doc_count = 3332956\n",
    "training_final = training_final.fillna(1)\n",
    "training_final['volume_count'] = pd.to_numeric(training_final.volume_count, errors='coerce')\n",
    "training_final['tf_idf'] =  training_final['frequency']/training_final['wordCount'] \n",
    "training_final['tf_idf'] =  training_final['tf_idf']*(training_final['volume_count'].apply(lambda x: math.log(doc_count/(2+x),10)))\n",
    "\n",
    "\n",
    "#### Adding the pos_rank - rank for every parts of speech ####\n",
    "training_final['pos_rank'] = 2\n",
    "training_final.loc[training_final.pos == 'NN' , 'pos_rank'] = 14\n",
    "training_final.loc[training_final.pos == 'JJ' , 'pos_rank' ] = 7\n",
    "training_final.loc[training_final.pos == 'NNS' , 'pos_rank'] = 6\n",
    "training_final.loc[training_final.pos == 'NNP' , 'pos_rank' ] = 6\n",
    "training_final.loc[training_final.pos == 'VBP' , 'pos_rank' ] = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5412, 12)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#### Scoring the training properties ####\n",
    "training_final['score'] = 0\n",
    "for index,row in training_final.iterrows():\n",
    "    score = ((row['pos_rank'] * row['n_gram_score']))*row['tf_idf'] \n",
    "    training_final.loc[index , 'score'] = score\n",
    "    \n",
    "training_final = training_final.sort_values(['score'], ascending=False)\n",
    "training_final_2 = training_final.copy()\n",
    "training_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MODEL 1 : Predicting using the clustering and scoring function ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#### Evaluating MODEL 1 ####\n",
    "def match_count(predicted, actual):\n",
    "    count = 0\n",
    "    pred_copy = predicted\n",
    "    act_copy = actual\n",
    "    for str in predicted:\n",
    "        if (actual.count(str) >= 1):\n",
    "            count = count + 1\n",
    "            act_copy.remove(str)\n",
    "            pred_copy.remove(str)\n",
    "    left_pred = pred_copy\n",
    "    left_act = act_copy[:]\n",
    "    match = False\n",
    "    for index in act_copy:\n",
    "            for str in pred_copy:\n",
    "                if(index.find(str) != -1):\n",
    "                    count = count + 1\n",
    "                    match = True\n",
    "                    left_pred.remove(str)\n",
    "                    \n",
    "            if match:\n",
    "                left_act.remove(index)\n",
    "    list = [count, len(pred_copy),len(act_copy)]\n",
    "    return list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Finding/Matching the indices in the training set ####\n",
    "\n",
    "def match_count1(predicted, actual):\n",
    "    count = 0\n",
    "    index_words = []\n",
    "    pred_copy = predicted\n",
    "    act_copy = actual\n",
    "    for str in predicted:\n",
    "        if (actual.count(str) >= 1):\n",
    "            count = count + 1\n",
    "            act_copy.remove(str)\n",
    "            pred_copy.remove(str)\n",
    "            index_words.append(str)\n",
    "    left_pred = pred_copy\n",
    "    left_act = act_copy[:]\n",
    "    match = False\n",
    "    for index in act_copy:\n",
    "            for str in pred_copy:\n",
    "                if(index.find(str) != -1):\n",
    "                    count = count + 1\n",
    "                    match = True\n",
    "                    left_pred.remove(str)\n",
    "                    index_words.append(str)\n",
    "            if match:\n",
    "                left_act.remove(index)\n",
    "    list = [count, len(pred_copy),len(act_copy),index_words]\n",
    "    return list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Reading the actual indices of the files used for training ####\n",
    "Indexes_Actual = pd.read_csv(\"Training_Indexes.csv\", low_memory=False)\n",
    "\n",
    "res = match_count1(list(training_final['word'].values) , list(Indexes_Actual['word'].values))\n",
    "\n",
    "\n",
    "def is_index():\n",
    "    training_final['is_index'] = 0\n",
    "    for item in res[3]:\n",
    "        training_final.loc[training_final.word == item  , 'is_index'] = 1\n",
    "        \n",
    "is_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vamsidhar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#### MODEL 2 : Logistic Regression ####\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "logistic = LogisticRegression(class_weight = \"balanced\")\n",
    "training_features = ['score']\n",
    "target = ['is_index']\n",
    "train_x , test_x, train_y , test_y = train_test_split(training_final[training_features] , training_final[target] , train_size=0.8)\n",
    "logistic.fit(train_x,train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64495264495264493"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#### Predicting for new files ####\n",
    "accuracy = logistic.score(train_x , train_y)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63619575253924288"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = logistic.score(test_x , test_y)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vamsidhar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51          unitary conjugation\n",
       "46                matrix convex\n",
       "10                free circular\n",
       "70                linear pencil\n",
       "163                 pencil ball\n",
       "120             circular matrix\n",
       "165           reducing subspace\n",
       "35                  cross terms\n",
       "303                  monic free\n",
       "130           free spectrahedra\n",
       "102                  direct sum\n",
       "78         unitarily equivalent\n",
       "166          separation theorem\n",
       "50                 spectrahedra\n",
       "129            free polynomials\n",
       "189               circular free\n",
       "309             operator pencil\n",
       "282                 free matrix\n",
       "1                        matrix\n",
       "310    orthogonal decomposition\n",
       "20                     subspace\n",
       "225       relatively irrational\n",
       "72            positive integers\n",
       "Name: word, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Evaluating MODEL 2 ####\n",
    "\n",
    "light_nuclei = training_final.loc[training_final_2.source == 1]\n",
    "\n",
    "training_features = ['score']\n",
    "test_x = light_nuclei[training_features]\n",
    "pred_y = logistic.predict(test_x)\n",
    "light_nuclei['is_index_pred'] = pred_y\n",
    "inds = light_nuclei.loc[light_nuclei.is_index_pred == 1]\n",
    "inds = inds.drop_duplicates(['word'],keep='first')\n",
    "inds = inds.sort_values(['score'], ascending=False)\n",
    "inds['word'][:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### MODEL 3 : Random Forest Regression/classifier ####\n",
    "\n",
    "## Using Random forests\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "regr = RandomForestRegressor(max_depth=10, random_state=0)\n",
    "\n",
    "training_features = ['tf_idf','score','n_gram_score']\n",
    "target = ['is_index']\n",
    "train_x , test_x, train_y , test_y = train_test_split(merged_circular[training_features] , merged_circular[target] , train_size=0.8)\n",
    "regr.fit(train_x,train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Evaluating MODEL 3 ####\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
